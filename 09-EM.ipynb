{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "# Практическое задание 9. EM-алгоритм\n",
    "\n",
    "## Общая информация\n",
    "Дата выдачи: 11.04.2020\n",
    "\n",
    "Мягкий дедлайн: 30.04.2020 07:00 MSK\n",
    "\n",
    "Жёсткий дедлайн: 03.05.2020 07:00 MSK\n",
    "\n",
    "## Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимальная оценка за работу (без учёта бонусов) — 15 баллов.\n",
    "\n",
    "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "## Формат сдачи\n",
    "Задания сдаются через систему anytask. Посылка должна содержать:\n",
    "* Ноутбук homework-practice-09-em-Username.ipynb\n",
    "* Модули preprocessing.py, quality.py, models.py, содержащие написанный вами код\n",
    "* Ссылки на посылки в Яндекс.Контест для всех функций и классов, которые вы реализовали\n",
    "\n",
    "Ссылка на Яндекс.Контест: https://contest.yandex.ru/contest/17827/\n",
    "\n",
    "Username — ваша фамилия и имя на латинице именно в таком порядке\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative model of Labels, Abilities, and Difficulties (GLAD)\n",
    "\n",
    "В [семинаре 15](https://github.com/esokolov/ml-course-hse/blob/master/2019-spring/seminars/sem15-em.pdf) мы рассмотрели задачу восстановления истинной разметки по меткам от экспертов (которым мы не можем доверять в полной мере, более того, их предсказания могут расходиться).\n",
    "\n",
    "Рассмотрим следующую вероятностную модель:\n",
    "\n",
    "$$ p(L, Z | \\alpha, \\beta) = \\prod_{i=1}^{n} \\prod_{j=1}^m \\sigma(\\alpha_j\\beta_i)^{[l_{ij}=z_i]}\\sigma(-\\alpha_j\\beta_i)^{1-[l_{ij}=z_i]} p(z_j)$$\n",
    "\n",
    "где $l_{ij} -$ ответ $j$-го эксперта на задачу $i$, $z_j -$ истинная разметка, $\\alpha_i, \\beta_j-$ уровень экспертизы и сложность задачи соответственно. Для более подробного описания модели можно прочитать материалы семинара, а также [оригинальную статью](http://papers.nips.cc/paper/3644-whose-vote-should-count-more-optimal-integration-of-labels-from-labelers-of-unknown-expertise.pdf). Априорное распределение положим равномерным: $p(z_i) = 0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "import scipy.optimize\n",
    "seed = 0xDEADF00D\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.load('L.npy')\n",
    "n, m = L.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1.** Реализуйте EM-алгоритм для заданной выше модели. Вы можете воспользоваться предложенными шаблонами или написать свои. \n",
    "\n",
    "Обратите внимание, что правдоподобие моделирует не вероятность метки $l_{ij}$ принять значение 1 или 0, а вероятность того, что она равна скрытой переменной $z_i$, т.е. $p(l_{ij} = z_j|z_j, \\alpha_j, \\beta_i) \\neq p(l_{ij} = 1|\\alpha_j, \\beta_i) $. При этом какая из скрытых переменных соответствует метке 1, заранее неизвестно. Не забывайте, что параметры $\\beta_i$ должны быть неотрицательными, для этого оптимизируйте $\\log \\beta$. \n",
    "\n",
    "Также при работе с вероятностями не забывайте о точности:\n",
    "1. Используйте логарифмы вероятностей.\n",
    "2. $\\log \\sigma(a)$ лучше преобразовать в $\\log \\sigma(a) = -\\log(1 + \\exp(-a)) = -\\mathrm{softplus}(-a) $\n",
    "3. Ещё полезные функции: `scipy.special.expit`, `scipy.special.logsumexp`, `np.log1p`\n",
    "\n",
    "Для отладки может быть полезно проверить градиент с помощью `scipy.optimize.check_grad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softplus(x):\n",
    "    '''stable version of log(1 + exp(x))'''\n",
    "    c = (x > 20) * 1.\n",
    "    return np.log1p(np.exp(x * (1-c)) * (1-c)) + x * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior(alpha, beta, L):\n",
    "    \"\"\" Posterior over true labels z p(z|l, \\alpha, \\beta)\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts).\n",
    "        beta: ndarray of shape (n_problems).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "    \"\"\"\n",
    "    ab = np.exp(beta).reshape(-1,1) * alpha.reshape(1,-1)\n",
    "    sigma_pos,sigma_neg = scipy.special.expit(ab), scipy.special.expit(-ab)\n",
    "    \n",
    "    pos = (L==1) * sigma_pos + (L!=1) * sigma_neg\n",
    "    neg = (L==0) * sigma_pos + (L!=0) * sigma_neg\n",
    "    \n",
    "    probZ = np.zeros((2, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        probZ[1][i] = np.sum(pos[i])\n",
    "        probZ[0][i] = np.sum(neg[i])\n",
    "    \n",
    "    probZ = np.exp(probZ)\n",
    "    probZ /= np.sum(probZ, axis=0)\n",
    "    return probZ\n",
    "\n",
    "\n",
    "def log_likelihood(alpha, beta, L, z):\n",
    "    \"\"\" p(l=z|z, \\alpha, \\beta)\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts).\n",
    "        beta: ndarray of shape (n_problems).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "        z: ndarray of shape (n_problems).\n",
    "    \"\"\"\n",
    "    ab = np.exp(beta).reshape(-1,1) * alpha.reshape(1,-1)\n",
    "    soft_pos = -softplus(-ab)\n",
    "    soft_neg = -softplus(ab)\n",
    "    prob = (L==z) * soft_pos + (L!=z) * soft_neg\n",
    "    prob = np.exp(prob)\n",
    "    return np.sum(prob, axis=1)\n",
    "\n",
    "def alpha_grad_lb(alpha, beta, L, q):\n",
    "    \"\"\" Gradient of lower bound wrt alpha\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts).\n",
    "        beta: ndarray of shape (n_problems).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "        q: ndarray of shape (2, n_problems).\n",
    "    \"\"\"\n",
    "    ab = np.exp(beta).reshape(-1,1) * alpha.reshape(1,-1)\n",
    "    sigma_pos = scipy.special.expit(ab) * np.exp(beta).reshape(-1, 1)\n",
    "    sigma_neg = scipy.special.expit(-ab) * np.exp(beta).reshape(-1, 1)\n",
    "    \n",
    "    pos = (L==1) * sigma_neg - (L!=1) * sigma_pos\n",
    "    neg = (L==0) * sigma_neg - (L!=0) * sigma_pos\n",
    "    \n",
    "    grad = np.sum(pos * q[1].reshape(-1, 1), axis=0) + np.sum(neg * q[0].reshape(-1, 1), axis=0)\n",
    "    return grad\n",
    "\n",
    "\n",
    "def logbeta_grad_lb(alpha, beta, L, q):\n",
    "    \"\"\" Gradient of lower bound wrt alpha\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts).\n",
    "        beta: ndarray of shape (n_problems).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "        q: ndarray of shape (2, n_problems).\n",
    "    \"\"\"\n",
    "    ab = np.exp(beta).reshape(-1,1) * alpha.reshape(1,-1)\n",
    "    sigma_pos,sigma_neg = scipy.special.expit(ab), scipy.special.expit(-ab)\n",
    "    \n",
    "    pos = ((L==1) * sigma_neg - (L!=1) * sigma_pos) * alpha.reshape(1,-1)\n",
    "    neg = ((L==0) * sigma_neg - (L!=0) * sigma_pos) * alpha.reshape(1,-1)\n",
    "    \n",
    "    grad = np.sum(neg * q[0].reshape(-1, 1), axis=1) + np.sum(pos * q[1].reshape(-1, 1), axis=1)\n",
    "    \n",
    "    return grad * np.exp(beta)\n",
    "\n",
    "\n",
    "def lower_bound(alpha, beta, L, q):\n",
    "    \"\"\" Lower bound\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts).\n",
    "        beta: ndarray of shape (n_problems).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "        q: ndarray of shape (2, n_problems).\n",
    "    \"\"\"\n",
    "    l = np.c_[log_likelihood(alpha, beta, L, 0), log_likelihood(alpha, beta, L, 1)]\n",
    "    a, b = np.sum(q * 0.5, axis=1)\n",
    "    r = np.dot(q, l)\n",
    "    return np.r_[r[0][0] + a, r[1][1] + b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x, *args):\n",
    "    alpha, beta = x[:m], x[m:]\n",
    "    return -lower_bound(alpha, beta, L, q)\n",
    "def grad(x, *args):\n",
    "    alpha, beta = x[:m], x[m:]\n",
    "    return -np.r_[alpha_grad_lb(alpha, beta, L, q), logbeta_grad_lb(alpha, beta, L, q)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.ones((2, n)) * 0.5\n",
    "def em(L, n_steps=1000, lr=1e-3):\n",
    "    # initialize parameters\n",
    "    alpha, logbeta = np.random.randn(m), np.random.randn(n)\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        # E-step\n",
    "        q = posterior(alpha, logbeta, L)\n",
    "        # M-step\n",
    "        res = scipy.optimize.fmin_l_bfgs_b(func, np.r_[alpha, logbeta], fprime=grad)[0]\n",
    "        alpha, logbeta = res[:m], res[m:]\n",
    "\n",
    "    return alpha, np.exp(logbeta), q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.** Загрузите настоящую разметку. Посчитайте `accuracy` разметки, полученной с помощью обычного голосования по большинству среди экспертов, и сравните его с качеством, полученным с помощью EM-алгоритма. Помните, что алгоритму не важно, какая метка 0, а какая 1, поэтому если получите качество <0.5, то просто поменяйте метки классов (не забудьте также поменять знак у $\\alpha$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.load('y.npy')\n",
    "# (∩ ￣ー￣)⊃ ✳✨✳✨✳✨✳\n",
    "alpha, beta, q = em(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(q[1] > 0.5, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.** Попробуйте проинтерпретировать полученные коэфициенты $\\alpha$. Есть ли в выборке эксперты, которые намеренно голосуют неверно? Как это можно понять по альфам? Продемонстрируйте, что эксперты действительно чаще голосуют за неверный класс. Постройте график зависимости доли врено размеченных экспертом объектов от коэффициента $\\alpha$. Прокомментируйте результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 0, 8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alpha[alpha < 0]), len(alpha[alpha==0]), len(alpha[alpha>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.bar(np.arange(m), alpha)\n",
    "plt.title('Alpha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из графика видно, что около 8 экспертов являются adversarial (то есть инвертируют известную им метку класса), примерно 3 имеют alpha=0, то есть их оценка не является значимой, и около 7 правильно определяют класс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for ind, al in enumerate(alpha):\n",
    "    res.append(np.sum(L[:,ind] == y) / len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(alpha, res)\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Зависимость доли верных ответов от alpha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как самая высокая доля правильных ответов, так и самая низкая наблюдаются и при alpha > 0 и при alpha < 0, для alpha близких к 0 доля правильных ответов примерно одинаковая (~0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4. (бонус, 2 балла)**  Как уже было замечено выше, модели не важно, какой класс 1, а какой 0. Скажем, если все эксперты оказались максимально противными и ставят метку с точностью наоборот, то у вас будет полная согласованность между экспертами, при этом невозможно понять правильно они разметили выборку или нет, смотря только на такую разметку. Чтобы избежать этого, можно включать в выборку вопрос с заведомо известным ответом, тогда вы сможете определить, ставит ли эксперт специально неверные метки.\n",
    "\n",
    "Чтобы обощить данную модель на случай заданий с заведомо известной меткой, достоточно не делать для них E-шаг, а всегда полагать апостериорное распределение вырожденным в истинном классе. Реализуйте данную модель и используйте истинную разметку *для нескольких* задач из обучения. Проинтерпретируйте полученные результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выравнивание слов (Word Alignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EM-алгоритм также применяют на практике для настройки параметров модели выравнивания слов, более сложные модификации которой используются в статистическом машинном переводе. Мы не будем подробно обсуждать применение word alignment для перевода и ограничимся следующей целью: пусть у нас есть параллельный корпус из предложений на исходном языке и их переводов на целевой язык (в этом задании используются английский и чешский соответственно). \n",
    "\n",
    "Первая задача — определить с помощью этого корпуса, как переводится каждое отдельное слово на целевом языке. Вторая задача — для произвольной пары из предложения и его перевода установить, переводом какого слова в исходном предложении является каждое слово в целевом предложении. Оказывается, у обеих задач существует элегантное и эффективное решение при введении правильной вероятностной модели: в этой части задания вам предстоит его реализовать и оценить результаты работы. Но обо всём по порядку :)\n",
    "\n",
    "---\n",
    "\n",
    "Перед тем, как заниматься машинным обучением, давайте разберёмся с данными и метриками в интересующей нас задаче. В ячейке ниже загружается и разархивируется параллельный английско-чешский корпус, в котором есть разметка выравнивания слов. Нетрудно заметить, что формат XML-файла, использованный его авторами, не вполне стандартный: нет готовой команды , которая позволила бы получить список пар предложений вместе с выравниваниями. Это значит, что нужно разобраться с форматом и написать парсер самостоятельно, используя встроенные средства Python, например, модуль [xml](https://docs.python.org/3.7/library/xml.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n",
      "<sentences>\n",
      "<s id=\"project_syndicate_bacchetta1-s1\">\r\n",
      "  <english>Are the Dollar 's Days Numbered ?</english>\n",
      "  <czech>Jsou dny dolaru sečteny ?</czech>\n",
      "  <sure>1-1 3-3 5-2 6-4 7-5</sure>\n",
      "  <possible>2-2 4-3</possible>\n",
      "</s>\n",
      "<s id=\"project_syndicate_bacchetta1-s2\">\r\n",
      "  <english>Philippe Bacchetta and Eric van Wincoop</english>\n",
      "  <czech>Philippe Bacchetta and Eric van Wincoop</czech>\n",
      "  <sure>1-1 2-2 3-3 4-4 5-5 6-6</sure>\n",
      "  <possible></possible>\n",
      "</s>\n",
      "<s id=\"project_syndicate_bacchetta1-s3\">\r\n",
      "  <english>A year ago , the dollar bestrode the world like a colossus .</english>\n",
      "  <czech>Ještě před rokem dolar dominoval světu jako imperátor .</czech>\n",
      "  <sure>10-7 12-8 13-9 2-3 3-2 6-4 7-5 9-6</sure>\n",
      "  <possible>1-3 11-8 3-1 5-4 8-6</possible>\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wget -q https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-1804/CzEnAli_1.0.tar.gz -O CzEnAli_1.0.tar.gz\n",
    "mkdir -p data\n",
    "tar -xzf CzEnAli_1.0.tar.gz -C data/\n",
    "head -n 20 data/merged_data/project_syndicate/project_syndicate_bacchetta1.wa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание -2.** Реализуйте функцию `extract_sentences`, которая принимает на вход путь к файлу с XML-разметкой, используемой в этом датасете, и возвращает список параллельных предложений, а также список из «уверенных» (sure) и «возможных» (possible) пар выравниваний. Отправьте вашу реализацию в Яндекс.Контест, чтобы убедиться в её корректности; в следующей ячейке ноутбука соберите все пары размеченных предложений из датасета в два списка `all_sentences` (список `SentencePair`) и `all_targets` (список LabeledAlignment).\n",
    "\n",
    "Здесь и далее соблюдайте сигнатуры функций и пользуйтесь объявленными в модуле `preprocessing.py` классами для организации данных. Стоит заметить, что предложения уже токенизированы (даже отделена пунктуация), поэтому предобработку текстов совершать не нужно. Обратите внимание на формат хранения выравниваний: нумерация начинается с 1 (в таком виде и нужно сохранять), первым в паре идёт слово из англоязычного предложения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Имя в контесте **Dilara KH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from preprocessing import extract_sentences\n",
    "\n",
    "all_sentences = []\n",
    "all_targets = []\n",
    "# (´◕▽◕)⊃━☆\n",
    "\n",
    "xml_file = 'data/merged_data/project_syndicate/project_syndicate_bacchetta1.wa'\n",
    "all_sentences, all_targets = extract_sentences(xml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание -1.** Реализуйте функции `get_token_to_index` и `tokenize_sents` из модуля `preprocessing.py`, постройте словари token->index для обоих языков и постройте список из `TokenizedSentencePair` по выборке. Реализации функций также отправьте в Яндекс.Контест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import get_token_to_index, tokenize_sents\n",
    "\n",
    "t_idx_src, t_idx_tgt = get_token_to_index(all_sentences)\n",
    "tokenized_sentences = tokenize_sents(all_sentences, t_idx_src, t_idx_tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве бейзлайна для этой задачи мы возьмём способ выравнивания слов по коэффициенту Дайса: слово в исходном языке является переводом слова на целевом языке, если они часто встречаются в одних и тех же предложениях и редко встречаются по отдельности. \n",
    "\n",
    "Математически это записывается по аналогии с мерой Жаккара: пусть $c(x,y)$ — число параллельных предложений, в которых есть и $x$ (на исходном языке), и $y$ (на целевом языке), а $c(x)$ и $c(y)$ — суммарное количество предложений, в которых встречается слово $x$ и $y$ соответственно. Тогда $\\textrm{Dice}(x,y)=\\frac{2 \\cdot c(x,y)}{c(x) + c(y)}$ — характеристика «похожести» слов $x$ и $y$. Она равна 1, если слова встречаются только в контексте друг друга (не бывает предложений только со словом $x$ без $y$ в переводе и наоборот), равна 0, если слова никогда не встречаются в параллельных предложениях и находится между пороговыми значениями в остальных случаях.\n",
    "\n",
    "В файле `models.py` описан абстрактный класс `BaseAligner`, наследником которого должны являться все модели в задании, а также приведён пример реализации `DiceAligner` выравнивания слов описанным выше путём. Ниже вы можете увидеть, как применять эту модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import DiceAligner\n",
    "\n",
    "baseline = DiceAligner(len(t_idx_src), len(t_idx_tgt), threshold=0.01)\n",
    "baseline.fit(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы оценить качество модели выравнивания, пользуясь имеющейся разметкой, существует ряд автоматических метрик. Они подразумевают, что в разметке есть два вида выравниваний — «уверенные» (sure) и «возможные» (possible). Обозначим для конкретного предложения первое множество выравниваний $S$, второе — $P$, а предсказанные выравнивания — $A$; причём, в отличие от разметки в файле, $S\\subseteq P$. Тогда можно предложить три метрики, используя только операции над этими множествами:\n",
    "\n",
    "Precision $=\\frac{|A\\cap P|}{|A|}$. Отражает, какая доля предсказанных нами выравниваний вообще корректна; если мы дадим в качестве ответа все возможные пары слов в предложении, эта метрика сильно просядет.\n",
    "\n",
    "Recall $=\\frac{|A\\cap S|}{|S|}$. Эта метрика показывает, какую долю «уверенных» выравниваний мы обнаружили. Если мы попытаемся сделать слишком консервативную модель, которая выдаёт 0 или 1 предсказание на нетривиальных предложениях, полнота получится крайне низкая. \n",
    "\n",
    "Alignment Error Rate (AER) $=1-\\frac{|A\\cap P|+|A\\cap S|}{|A|+|S|}$. Метрика является комбинацией двух предыдущих и отслеживает общее качество работы системы, штрафуя оба описанных выше вида нежелаемого поведения модели. \n",
    "\n",
    "**Задание 0.** Реализуйте функции compute_precision, compute_recall, compute_aer из модуля quality.py. Оцените качество бейзлайнового метода. Обратите внимание, что нужно использовать микро-усреднение во всех функциях: необходимо просуммировать числитель и знаменатель по всем предложениям и только потом делить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89587852494577"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from quality import compute_aer\n",
    "\n",
    "compute_aer(all_targets,baseline.align(tokenized_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем перейти к базовой вероятностной модели для выравнивания слов. Пусть $S=(s_1,\\ldots,s_n)$ исходное предложение, $T=(t_1,\\ldots,t_m)$ — его перевод. В роли латентных переменных будут выступать выравнивания $A=(a_1,\\ldots,a_m)$ каждого слова в целевом предложении, причём $a_i\\in\\{1,\\ldots,n\\}$ (считаем, что каждое слово в $t$ является переводом какого-то слова из $s$). Параметрами модели является матрица условных вероятностей перевода: каждый её элемент $\\theta(y|x)=p(y|x)$ отражает вероятность того, что переводом слова $x$ с исходного языка на целевой является слово $y$ (нормировка, соответственно, совершается по словарю целевого языка). Правдоподобие латентных переменных и предложения на целевом языке в этой модели записывается так:\n",
    "\n",
    "$$\n",
    "p(A,T|S)=\\prod_{i=1}^m p(a_i)p(t_i|a_i,S)=\\prod_{i=1}^m \\frac{1}{n}\\theta(t_i|s_{a_i}).\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1.** Выведите шаги EM-алгоритма для этой модели, а также получите выражение для подсчёта нижней оценки правдоподобия ($\\mathcal{L}$ в обозначениях лекции и семинара). Обратите внимание, что на M-шаге нужно найти аналитический максимум по параметрам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E-step\n",
    "$$\n",
    "q^{*}(a) = p(a | t, s) = \\frac{p(a, t | s)}{p(t | s)}\n",
    "$$\n",
    "Найдём $p(t | s)$\n",
    "$$\n",
    "p(t | s) = \\sum_a p(t,a|s) = \\sum_a \\prod_{j=1}^{m} \\frac{1}{n} \\theta(t_j | s_{a_j})\n",
    "$$\n",
    "Тогда $$\n",
    "q^{*}(a) =  \\frac{p(a, t | s)}{p(t | s)} = \\prod_{j=1}^{m} \\frac{\\theta(t_j | s_{a_j})}{\\sum_{i=0}^{n}\\theta(t_j | s_{i})}\n",
    "$$\n",
    "Соответственно $q^{*}(a_j) = \\frac{\\theta(t_j | s_{a_j})}{\\sum_{i=0}^{n}\\theta(t_j | s_{i})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\log p(a,t) = -m \\log{n} + \\sum_{i=1}^{m} \\log \\theta(t_i |s_{a_i})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.** Реализуйте все методы класса `WordAligner` в соответствии с полученными вами формулами. Протестируйте вашу реализацию через Яндекс.Контест, а здесь обучите модель и посчитайте её AER на истинной разметке. Чтобы предсказать выравнивание для пары предложений в этой модели, следует выбирать в соответствие для слова в целевом предложении с индексом $i$ позицию, соответствующую максимуму апостериорного распределения $p(a_i|T,S)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import WordAligner\n",
    "\n",
    "word_aligner = WordAligner(len(t_idx_src), len(t_idx_tgt), 20)\n",
    "word_aligner.fit(tokenized_sentences);\n",
    "\n",
    "# ༼つ ಠ益ಠ༽つ ─=≡ΣO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что таблицу вероятностей перевода можно использовать и саму по себе для построения словарей. Пример работы показан ниже: метод хоть и работает, но мягко говоря, неидально — слишком мало данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_token_tgt = {index:token for token, index in t_idx_tgt.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pan', 'řekl', 'pan']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['Mr']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-', 'Mannová', 'paní']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['Mrs']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['z', 'pro', 'vody']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['water']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dne', 'koni', 'záviselo']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['depended']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.', 'se', 'na']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['on']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.** Мы смогли получить матрицу условных вероятностей перевода исходного языка в целевой. Можно ли, пользуясь этой матрицей и ещё какими-то статистиками по параллельному корпусу, получить вероятности перевода целевого языка в исходный? Реализуйте такой метод и приведите ниже пример его работы, показав пару удачных переводов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (>ω<)ノ—==ΞΞ☆*✲ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4.** Визуализируйте полученные выравнивания для нескольких предложений в виде heatmap: по одной из осей располагаются токены исходного текста, по другой — токены его перевода, на пересечении позиций $i$ и $j$ — 0 либо 1 в зависимости от того, является ли в обученной модели $a_i$ равным $j$. Можете ли вы их проинтерпретировать? Постройте аналогичный график, но без дискретизации, а визуализируя напрямую апостериорное распределение. Можете ли вы найти ситуации, в которых модель не уверена, переводом какого слова является слово $i$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (•̀ 3 •́)━★☆.*･｡ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что при задании модели мы сделали довольно сильное предположение о том, что вероятности выбора слова для выравнивания никак не зависят от позиции слова в целевом предложении. Можно сделать эти вероятности настраиваемыми параметрами, получив прямоугольную матрицу $\\phi_{m,n}(j|i)=p(a_i=j|m,n)$ для каждой пары длин предложений $m,n$: по-прежнему мы получаем распределение над индексами в исходном предложении. Тогда модель приобретает вид\n",
    "$$\n",
    "p(A,T|S)=\\prod_{i=1}^m p(a_i|m,n)p(t_i| a_i, S)=\\prod_{i=1}^m \\phi_{m,n}(a_i|i)\\theta(t_i|s_{a_i}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 5.** Выведите шаги EM-алгоритма для этой модели, а также получите выражение для подсчёта нижней оценки правдоподобия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ଘ(๑˃̵ᴗ˂̵)━☆ﾟ.*･｡ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6.** Реализуйте все методы класса `WordPositionAligner`, протестируйте их корректность через Яндекс.Контест. Обучите модель, оцените её качество на истинной разметке и сравните его с качеством предыдущей более простой модели. Проиллюстрируйте влияние стартовых параметров на результат, проинициализировав эту модель параметрами модели из задания 2 (важно, чтобы суммарное число эпох обучения в обоих сценариях оставалось тем же)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import WordPositionAligner\n",
    "# (≧ ◡ ≦)━★☆.*･｡ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 7 (бонус, до 3 баллов).** \n",
    "\n",
    "Улучшите качество получившейся системы настолько, насколько сможете. За каждые 5 процентов, на которые AER на тех же данных получается меньше, чем минимум ошибки всех предыдущих моделей, вы получите по 1 бонусному баллу.\n",
    "\n",
    "Ниже приведены несколько идей, которые могут помочь вам повысить \n",
    "\n",
    "* Модифицировать модель: как вы можете понять, недостатком второго реализованного вами подхода является избыточное число параметров из-за необходимости подерживать отдельную матрицу для каждой различной пары длин предложений в корпусе. В статье https://www.aclweb.org/anthology/N13-1073.pdf приведён способ снижения числа параметров, задающих априорное распределение позиций выравнивания, который позволяет в десять раз быстрее обучать модель и получать лучшее качество.\n",
    "* Предобработка текстов: мы никак не заостряли внимание на этом шаге, но сейчас токенизация чувствительна к регистру, а слова на чешском языке вдобавок обладают богатой морфологией и большим количеством диакритических знаков. Если сократить количество параметров модели (различных слов), можно ускорить обучение и добиться лучших результатов, потому что статистики по словам будут считаться по большему числу параллельных предложений.\n",
    "* Агрегация по двум направлениям: в статье https://www.aclweb.org/anthology/J03-1002/ утверждается, что асимметричность выравниваний вредит качеству, потому что из-за выбранной модели одному слову в целевом предложении не может соответствовать два слова в исходном предложении. Для решения этой проблемы (и улучшения метрик, разумеется) авторы предлагают несколько алгоритмов, которые можно попробовать применить в этом задании.\n",
    "* Использовать больше обучающих данных. В корпусе, которым мы пользуемся, только пара тысяч предложений, чего может не хватать для по-настоящему хорошей модели выравнивания. Разумеется, неразмеченных параллельных английско-чешских корпусов гораздо больше, поэтому можно воспользоваться ими. Хорошая точка для старта — данные с соревнования по машинному переводу  [воркшопа WMT](http://www.statmt.org/wmt20/translation-task.html).\n",
    "* В языках часто существуют слова наподобие артиклей или предлогов, которым не соответствует ни одно слово в переводе. Все рассмотренные в рамках задания модели это не учитывают, возможно, добавление возможности перевода в «нулевой» токен улучшит качество модели (при тестировании такие выравнивания имеет смысл выбрасывать)\n",
    "\n",
    "Если вы захотите улучшить качество модели путём улучшения предобработки или добавления данных, помните, что оно не должно приводить к удалению предложений из тестовых данных из-за отсутствия слов в построенном словаре. Если такое всё же произошло, для корректности сравнения считайте AER вашей модели на удалённых предложениях равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ┐_(ツ)_┌━☆ﾟ.*･｡ﾟ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
